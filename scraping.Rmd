---
title: "Scraping"
author: "Joe Marlo"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Scraping

```{r}
library(dplyr)
library(rvest)

download_and_unzip <- function(url_file, dest = 'data'){
  dir.create(dest)
  path_to_zip <- file.path(dest, 'temp_data.zip')
  download.file(url_file, destfile = path_to_zip)
  unzip(path_to_zip, exdir = dest)
  file.remove(path_to_zip)
}

read_page <- function(url_page){
  # read page
  page <- read_html(url_page)

  # find the links
  # first, examine the webpage using developer tools within your browser
  url_files <- page %>%
    html_elements('a') %>% # this selects all "a" html elements
    html_attr('href') # this extracts the html attribute "href"
  
  # make sure all links are zip files
  url_zips <- stringr::str_subset(url_files, "zip$")
  
  # add base url
  url_zips <- glue::glue('https://ftp.rma.usda.gov/{url_zips}')
  
  return(url_zips)
}

read_year_and_download <- function(year){
  # construct url and find the files
  base_url <- glue::glue('https://ftp.rma.usda.gov/pub/references/adm_livestock/{year}/')
  found_files <- read_page(base_url)
  
  # download the files
  purrr::map(found_files, download_and_unzip)
}

# download and unzip all the files in all the years
purrr::map(2014:2022, read_year_and_download)
```

